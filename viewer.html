<!DOCTYPE html>
<html >
<head>
    <meta charset="UTF-8">
    <title>An emotion-based video player</title>
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="css/emoticon.css">
    <link rel="stylesheet" href="css/content.css">
    <link type="text/css" rel="stylesheet" href="css/video-js.min.css" />
    <link href="//vjs.zencdn.net/5.8/video-js.min.css" rel="stylesheet">
    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <!-- Custom CSS -->
    <link href="css/logo-nav.css" rel="stylesheet">
    <link href="css/content.css" rel="stylesheet">
    <link type="text/css" rel="stylesheet" href="https://vjs.zencdn.net/4.12/video-js.css" />
    <script>
        // getUserMedia only works over https in Chrome 47+, so we redirect to https. Also notify user if running from file.
        if (window.location.protocol == "file:") {
            alert("You seem to be running this example directly from a file. Note that these examples only work when served from a server or localhost due to canvas cross-domain restrictions.");
        } else if (window.location.hostname !== "localhost" && window.location.protocol !== "https:"){
            window.location.protocol = "https";
        }
    </script>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Bootstrap Core JavaScript -->
    <script src="js/jquery/dist/jquery.js"></script>
    <script src="js/bootstrap.min.js"></script>
</head>
<body>
    <link href="css/default.css" rel="stylesheet">
    <script src="https://www.youtube.com/iframe_api"></script>

    <script src="js/utils.js"></script>
    <script src="js/clmtrackr/clm.js"></script>
    <script src="js/clmtrackr/clmtrackr.js"></script>
    <script src="js/models/model_pca_20_svm_emotionDetection.js"></script>
    <script src="js/clmtrackr/Stats.js"></script>
    <script src="js/models/d3.min.js"></script>
    <script src="js/models/emotion_classifier.js"></script>
    <script src="js/models/emotionmodel.js"></script>

    <script src="https://www.gstatic.com/firebasejs/3.1.0/firebase.js"></script>

    <!-- Navigation -->
    <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
        <div class="container">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="#">
                    <img src="http://placehold.it/150x50&text=Logo" alt="">
                </a>
            </div>
            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav">
                    <li>
                        <a href="expressions.html" target="content">Expressions</a>
                    </li>
                    <li>
                        <a href="viewer.html" target="content">Watch it!</a>
                    </li>
                    <li>
                        <a href="timeline.html" target="content">Results</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>
    
    <!-- Page Content -->
    <div class="text-container">
        <div class="row">
            <div class="col-lg-12">
                <h1>Watch it!</h1>
                <p>This demo is used to track participants' facial features and to analyse their emotional response to on-screen media.</p>
            </div>
        </div>
    </div>
    
    <div id="player"></div>
    <video id="videoel" width="400" height="300" preload="auto" loop hidden></video>
    <script>
        // 2. This code loads the IFrame Player API code asynchronously.
        var tag = document.createElement('script');

        tag.src = "https://www.youtube.com/iframe_api";
        var firstScriptTag = document.getElementsByTagName('script')[0];
        firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

        // 3. This function creates an <iframe> (and YouTube player)
        //    after the API code downloads.
        var player;
        function onYouTubeIframeAPIReady() {
            player = new YT.Player('player', {
                height: '390',
                width: '640',
                videoId: 'M7lc1UVf-VE',
                events: {
                    'onReady': onPlayerReady
                }
            });
        }

        // 4. The API will call this function when the video player is ready.
        function onPlayerReady(event) {
            event.target.playVideo();
        }

        function stopVideo() {
            player.stopVideo();
        }

        // Initialize Firebase
        var config = {
            apiKey: "AIzaSyBI1lAq_sWUkSyuw6_q9Tp4Xq57pTqQLUU",
            authDomain: "neurocinema-a859d.firebaseapp.com",
            databaseURL: "https://neurocinema-a859d.firebaseio.com",
            storageBucket: "neurocinema-a859d.appspot.com",
        };
        firebase.initializeApp(config);

        var vid = document.getElementById('videoel');
        // document.getElementById('youtube_player').style.visibility = 'hidden';

        /********** check and set up video/webcam **********/
        function enablestart() {
            var startbutton = document.getElementById('startbutton');
            startbutton.value = "start";
            startbutton.disabled = null;
            var showbutton = document.getElementById('showplayer');
            showbutton.disabled = null;
        }

        navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;
        window.URL = window.URL || window.webkitURL || window.msURL || window.mozURL;

        // check for camerasupport
        if (navigator.getUserMedia) {
            // set up stream
            var videoSelector = {video : true};
            if (window.navigator.appVersion.match(/Chrome\/(.*?) /)) {
                var chromeVersion = parseInt(window.navigator.appVersion.match(/Chrome\/(\d+)\./)[1], 10);
                if (chromeVersion < 20) {
                    videoSelector = "video";
                }
            };
        
            navigator.getUserMedia(videoSelector, function( stream ) {
                if (vid.mozCaptureStream) {
                    vid.mozSrcObject = stream;
                } else {
                    vid.src = (window.URL && window.URL.createObjectURL(stream)) || stream;
                }
                vid.play()
            }, function() {
                //insertAltVideo(vid);
                alert("There was some problem trying to fetch video from your webcam. If you have a webcam, please make sure to accept when the browser asks for access to your webcam.");
            });
        } else {
            //insertAltVideo(vid);
            alert("This demo depends on getUserMedia, which your browser does not seem to support. :(");
        }

        var today = new Date();
        var day = parseInt(today.toISOString().replaceAll('-','').split('T')[0])
        var data = 'emotion'
        var path = data + '/' + today.toISOString().replaceAll(':','')
        path = path.replaceAll('-','').replace('.','')
        /*********** setup of emotion detection *************/
        var last = ""; //["", "", "", ""];
        var timestamp = ""; //["", "", "", ""];
        var enames = ["angry", "sad", "surprised", "happy"]
        var ctrack = new clm.tracker({useWebGL : true});
        ctrack.init(pModel);

        for (var i = 0;i < enames.length; i++) {
            // init firebase
            firebase.database().ref(path + '/' + enames[i]).set({
                localisation: [{
                    sublocalisations: {
                        localisation: [],
                    },
                    type: "segments",
                    tcin: "00:00:00.0000",
                    tcout: "00:60:00.0000",
                    tclevel: 0
                }],
                id: enames[i],
                type: "segments",
                algorithm: "clmtrackr",
                processor: "R. Trachel",
                processed: day,
                version: 1
            });
        }

        function writeEmotionSegment(videoID, min, sec, ms) {
            if (last == "") {
                last = videoID
            }
            if (timestamp == "") {
                console.log('getting: ' + timestamp)
                timestamp = "00:".concat(min).concat(":").concat(sec).concat(".").concat(ms)
            } else {
                if (last == videoID) {
                    // remember only the first time stamp
                    console.log('not saving timestamp...')
                } else {
                    console.log('writing timestamp' + timestamp)
                    var ref = firebase.database().ref(path + '/' + videoID + '/localisation/0/sublocalisations/localisation');
                    // sync down from server
                    var list = [];
                    ref.on('value', function(snap) { list = snap.val(); });
                    // this is the correct way to change an array
                    list.push({
                        tcin: timestamp,
                        tcout: "00:".concat(min).concat(":").concat(sec).concat(".").concat(ms),
                        tclevel: 1
                    });
                    ref.set(list);
                    console.log('writting: ' + timestamp)
                    timestamp = "";
                    last = "";
                }
            }
        }

        function drawLoop() {
            requestAnimFrame(drawLoop);
            var cp = ctrack.getCurrentParameters();
            var er = ec.meanPredict(cp);
            var ts = player.getCurrentTime();
            if (er) {
                for (var i = 0;i < er.length;i++) {
                    if (er[i].value > 0.8) {
                        // console.log(enames[i] + ': ' + er[i].value)
                        var minnow = String(ts / 60).split('.')[0].pad(2);
                        var secnow = String(ts).split('.')[0].pad(2);
                        var msnow = String(String(ts).split('.')[1]).substr(0,4)
                        writeEmotionSegment(enames[i], minnow, secnow, msnow);
                    }
                }
            }
        }
        
        var ec = new emotionClassifier();
        ec.init(emotionModel);
        var emotionData = ec.getBlank();    
        
        ctrack.start(vid);
        // start loop to draw face
        drawLoop();
        // load video
        player.requestFullscreen();
        // start playing
        player.play();
        
        </script>
    </body>
</html>
